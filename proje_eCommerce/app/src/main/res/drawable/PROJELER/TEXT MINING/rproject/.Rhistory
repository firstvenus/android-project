positiveFile <- file.choose()
positiveWords <-read.delim("positive-words.txt")
positiveWords <-read.delim("positive-words.txt")
negativeFile <- file.choose()
negativeWords <- read.delim("negative-words.txt")
positiveWords <- scan("positive-words.txt", what= 'character')
negativeWords <- scan("negative-words.txt", what= 'character')
negativeWords <- c(negativeWords, 'horrible','bad','wtf')
positiveWords <- c(positiveWords, 'good','amazing','fantastic')
sentiment_Score = <- function(tweets,positiveWords,negativeWords, .progress='none'){}
sentiment_Score <- function(tweets, positiveWords, negativeWords, .progress='none'){}
require(plyr)
require,
require(plyr)
#reading data for positive and negative words
positivefile <- file.choose()
positive_words <- read.delim("positive-words.txt")
negativefile <- file.choose()
negative_words <- read.delim("negative-words.txt")
#getting words
positive_words <- scan("positive-words.txt", what = 'character')
negative_words <- scan("negative-words.txt", what = 'character')
negative_words <- c(negative_words, 'wtf', 'shitty', 'sucks')
install.packages("stringr")
install.packages("plyr")
#sentiment analysis
sentimentScore <- function(tweets, positive_words, negative_words, .progress='none')
{
require(plyr)
require(stringr)
scores = laply(sentences, function(tweets, positive_words, negative_words) {
# cleaning
tweets = gsub('[[:punct:]]', '', tweets)
tweets = gsub('[[:cntrl:]]', '', tweets)
tweets = gsub('\\d+', '', tweets)
# and convert to lower case:
tweets = tolower(tweets)
# split into words. str_split is in the stringr package
word.list = str_split(tweets, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
positive.matches = match(words, positive_words)
negative.matches = match(words, negative_words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
positive.matches = !is.na(positive.matches)
negative.matches = !is.na(negative.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(positive.matches) - sum(negative.matches)
return(score)
}, positive_words, negative_words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
result <- sentimentScore(data$text,positive_words,negative_words)
#sentiment analysis
sentimentScore <- function(tweets, positive_words, negative_words, .progress='none')
{
require(plyr)
require(stringr)
scores = laply(sentences, function(tweets, positive_words, negative_words) {
# cleaning
tweets = gsub('[[:punct:]]', '', tweets)
tweets = gsub('[[:cntrl:]]', '', tweets)
tweets = gsub('\\d+', '', tweets)
# and convert to lower case:
tweets = tolower(tweets)
# split into words. str_split is in the stringr package
word.list = str_split(tweets, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
positive.matches = match(words, positive_words)
negative.matches = match(words, negative_words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
positive.matches = !is.na(positive.matches)
negative.matches = !is.na(negative.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(positive.matches) - sum(negative.matches)
return(score)
}, positive_words, negative_words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
result <- sentimentScore(data$text,positive_words,negative_words)
install.packages('plyr')
library(plyr)
install.packages('stringr')
library(stringr)
result <- sentimentScore(data$text,positive_words,negative_words)
summary(result$score)
hist(result$score, main = "Histogram for Tweets", ylab = "Count of Tweets", border = "blue", col = "green", ylim = c(0,500))
dataFile <- file.choose()
mydata <- read.csv(dataFile)
hist(result$score, main = "Histogram for Tweets", ylab = "Count of Tweets", border = "blue", col = "green", ylim = c(0,500))
hist(result$score, main = "Tweet Histogram", ylab = "Tweet Count", border = "black", col = "red", ylim = c(0,500))
View(dataFile)
View(mydata)
View(mydata)
View(result)
view(positive_words)
plot(result)
plot(positive_words,negative_words)
plot(mydata)
plot(result, type="1")
plot(result, Type1Font())
barplot(result)
barplot(result.Length)
if(!require(wordcloud)) {install.packages("wordcloud")}
library(wordcloud)
#generate wordcloud
wordcloud(tweets.text.corpus,min.freq = 2, scale=c(7,0.5),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 150)
if(!require(wordcloud)) {install.packages("wordcloud")}
library(wordcloud)
#generate wordcloud
wordcloud(result$score,min.freq = 2, scale=c(7,0.5),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 150)
if(!require(wordcloud)) {install.packages("wordcloud")}
library(wordcloud)
#generate wordcloud
wordcloud(result,min.freq = 2, scale=c(7,0.5),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 150)
if(!require(wordcloud)) {install.packages("wordcloud")}
library(wordcloud)
#generate wordcloud
wordcloud(result)
if(!require(wordcloud)) {install.packages("wordcloud")}
library(wordcloud)
#generate wordcloud
wordcloud(mydata)
install.packages("tm")
if(!require(wordcloud)) {install.packages("wordcloud")}
library(wordcloud)
#generate wordcloud
wordcloud(mydata)
if(!require(wordcloud)) {install.packages("wordcloud")}
library(wordcloud)
#generate wordcloud
wordcloud(mydata,min.freq = 2, scale=c(7,0.5),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 150))
if(!require(wordcloud)) {install.packages("wordcloud")}
library(wordcloud)
#generate wordcloud
wordcloud(mydata,min.freq = 2, scale=c(7,0.5),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 150)
head(result,10)
barplot(d[1:10,]$freq, las = 2, names.arg = d[1:10,]$word,
col ="lightblue", main ="Most frequent words",
ylab = "Word frequencies")
barplot(result[1:10,]$freq, las = 2, names.arg = d[1:10,]$word,
col ="lightblue", main ="Most frequent words",
ylab = "Word frequencies")
barplot(result[1:10,]$freq, las = 2, names.arg = result[1:10,]$word,
col ="lightblue", main ="Most frequent words",
ylab = "Word frequencies")
